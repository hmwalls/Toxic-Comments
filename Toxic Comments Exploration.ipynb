{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import pandas_profiling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unan_comments = pd.read_csv('toxicity_annotated_comments_unanimous.tsv', sep='\\t')\n",
    "unan_scores = pd.read_csv('toxicity_annotations_unanimous.tsv', sep='\\t')\n",
    "\n",
    "# remove newline and tab tokens\n",
    "unan_comments['comment'] = unan_comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "unan_comments['comment'] = unan_comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_score = pd.merge(unan_comments, unan_scores, on='rev_id')\n",
    "split = comment_score.groupby('toxicity')\n",
    "\n",
    "toxic_group = split.get_group(1).groupby('comment')\n",
    "nontoxic_group = split.get_group(0).groupby('comment')\n",
    "\n",
    "toxics = []\n",
    "nontoxics = []\n",
    "all_comments = comment_score['comment']\n",
    "\n",
    "for name, group in toxic_group:\n",
    "    toxics.append(name)\n",
    "\n",
    "for name, group in nontoxic_group:\n",
    "    nontoxics.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transform\n",
    "toxic_vectorizer = TfidfVectorizer()\n",
    "nontoxic_vectorizer = TfidfVectorizer()\n",
    "all_vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "toxic_vectorizer.fit(toxics)\n",
    "nontoxic_vectorizer.fit(nontoxics)\n",
    "all_vectorizer.fit(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize\n",
    "print(all_vectorizer.vocabulary_)\n",
    "print(\"-------------------------\")\n",
    "print(all_vectorizer.idf_)\n",
    "\n",
    "toxic_vocab_words = toxic_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_vocab = pd.Series(toxic_vectorizer.vocabulary_)\n",
    "toxic_vocab1 = pd.Series(toxic_vocab.index.values, index=toxic_vocab )\n",
    "toxic_vocab_tfidf = pd.Series(toxic_vectorizer.idf_)\n",
    "toxic_vocab_score = pd.concat([toxic_vocab1, toxic_vocab_tfidf], keys=['Words','Scores'], axis=1)\n",
    "\n",
    "nontoxic_vocab = pd.Series(nontoxic_vectorizer.vocabulary_)\n",
    "nontoxic_vocab1 = pd.Series(nontoxic_vocab.index.values, index=nontoxic_vocab )\n",
    "nontoxic_vocab_tfidf = pd.Series(nontoxic_vectorizer.idf_)\n",
    "nontoxic_vocab_score = pd.concat([nontoxic_vocab1, nontoxic_vocab_tfidf], keys=['Words','Scores'], axis=1)\n",
    "\n",
    "all_vocab = pd.Series(all_vectorizer.vocabulary_)\n",
    "all_vocab1 = pd.Series(all_vocab.index.values, index=all_vocab )\n",
    "all_vocab_tfidf = pd.Series(all_vectorizer.idf_)\n",
    "all_vocab_score = pd.concat([all_vocab1, all_vocab_tfidf], keys=['Words','Scores'], axis=1)\n",
    "\n",
    "merged = pd.merge(nontoxic_vocab_score, toxic_vocab_score, on=\"Words\")\n",
    "merged = pd.merge(merged, all_vocab_score, on=\"Words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diff_non_toxic = []\n",
    "score_diff_non_all = []\n",
    "score_diff_toxic_all = []\n",
    "\n",
    "\n",
    "for index, row in merged.iterrows():\n",
    "    score_diff_non_toxic.append(row['Scores_x'] - row['Scores_y'])\n",
    "    score_diff_toxic_all.append(row['Scores_y'] - row['Scores'])\n",
    "    score_diff_non_all.append(row['Scores_x'] - row['Scores'])\n",
    "    \n",
    "merged['Score Diff, Toxic and Non-Toxic'] = score_diff_non_toxic\n",
    "merged['Score Diff, All and Non-Toxic'] = score_diff_non_all\n",
    "merged['Score Diff, All and Toxic'] = score_diff_toxic_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
